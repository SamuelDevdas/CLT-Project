{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjzYBNa9c-dh"
      },
      "source": [
        "# Stage 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsjm81-xdBT5"
      },
      "source": [
        "# Accelerating Cleantech Advancements through NLP-Powered Text Mining\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9JPhWcP4P-y"
      },
      "source": [
        "## Data Collection and Cleaning Tutorial for Cleantech NLP Project\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cpb8JDnR4b83"
      },
      "source": [
        "In this tutorial, we will go through the steps of collecting and cleaning data for our Cleantech NLP project. We have two main datasets: the Cleantech Media Dataset and the Cleantech Google Patent Dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MM0aoEWN7BTS"
      },
      "source": [
        "## Setting up the Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ua1bUqoM7D1C"
      },
      "source": [
        "We begin by mounting the Google Drive to access the datasets stored there. This step is necessary to read the data into our Colab notebook for analysis and cleaning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZYcqCNN7Qnz"
      },
      "source": [
        "## Loading the Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzhjV1RZ7VT-"
      },
      "source": [
        "Load the datasets into pandas DataFrames to prepare for exploration and cleaning.\n",
        "\n",
        "The media dataset is in CSV format, while the patent dataset is in JSON format, reflecting the structured nature of patent data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "yS0r8GZc_Qm1"
      },
      "outputs": [],
      "source": [
        "# Samuels drive link\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# Paths to the datasets\n",
        "cleantech_media_path = \"cleantech_media_dataset_v2_2024-02-23.csv\"\n",
        "cleantech_patent_path = \"cleantech_rag_evaluation_data_2024-02-23.csv\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "bb5WoO3i7bF1"
      },
      "outputs": [],
      "source": [
        "# Loading the datasets\n",
        "cleantech_media_data = pd.read_csv(cleantech_media_path)\n",
        "cleantech_patent_data = pd.read_csv(cleantech_patent_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_uc0SOFY3lt"
      },
      "source": [
        "## Initial Data Exploration\n",
        "\n",
        "Before cleaning, we need to understand our data, which includes checking the shape, examining the columns, and identifying any immediate issues such as missing values or inconsistent data types.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6fyTLJP-eXa",
        "outputId": "9c51b787-3670-4685-b322-aee4f8173a71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initial Cleantech Media Data shape: (9593, 8)\n",
            "Initial Cleantech Patent Data shape: (23, 5)\n"
          ]
        }
      ],
      "source": [
        "# Display the initial shape of the datasets\n",
        "print(\"Initial Cleantech Media Data shape:\", cleantech_media_data.shape)\n",
        "print(\"Initial Cleantech Patent Data shape:\", cleantech_patent_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kSCzZi-M-J0",
        "outputId": "2e549b56-2021-4719-9da5-ef60dd4be659"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>date</th>\n",
              "      <th>author</th>\n",
              "      <th>content</th>\n",
              "      <th>domain</th>\n",
              "      <th>url</th>\n",
              "      <th>Unnamed: 7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1280</td>\n",
              "      <td>Qatar to Slash Emissions as LNG Expansion Adva...</td>\n",
              "      <td>2021-01-13</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"Qatar Petroleum ( QP) is targeting aggressiv...</td>\n",
              "      <td>energyintel</td>\n",
              "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1281</td>\n",
              "      <td>India Launches Its First 700 MW PHWR</td>\n",
              "      <td>2021-01-15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"• Nuclear Power Corp. of India Ltd. ( NPCIL)...</td>\n",
              "      <td>energyintel</td>\n",
              "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1283</td>\n",
              "      <td>New Chapter for US-China Energy Trade</td>\n",
              "      <td>2021-01-20</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"New US President Joe Biden took office this ...</td>\n",
              "      <td>energyintel</td>\n",
              "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1284</td>\n",
              "      <td>Japan: Slow Restarts Cast Doubt on 2030 Energy...</td>\n",
              "      <td>2021-01-22</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"The slow pace of Japanese reactor restarts c...</td>\n",
              "      <td>energyintel</td>\n",
              "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1285</td>\n",
              "      <td>NYC Pension Funds to Divest Fossil Fuel Shares</td>\n",
              "      <td>2021-01-25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[\"Two of New York City's largest pension funds...</td>\n",
              "      <td>energyintel</td>\n",
              "      <td>https://www.energyintel.com/0000017b-a7dc-de4c...</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                              title        date  \\\n",
              "0        1280  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n",
              "1        1281               India Launches Its First 700 MW PHWR  2021-01-15   \n",
              "2        1283              New Chapter for US-China Energy Trade  2021-01-20   \n",
              "3        1284  Japan: Slow Restarts Cast Doubt on 2030 Energy...  2021-01-22   \n",
              "4        1285     NYC Pension Funds to Divest Fossil Fuel Shares  2021-01-25   \n",
              "\n",
              "  author                                            content       domain  \\\n",
              "0    NaN  [\"Qatar Petroleum ( QP) is targeting aggressiv...  energyintel   \n",
              "1    NaN  [\"• Nuclear Power Corp. of India Ltd. ( NPCIL)...  energyintel   \n",
              "2    NaN  [\"New US President Joe Biden took office this ...  energyintel   \n",
              "3    NaN  [\"The slow pace of Japanese reactor restarts c...  energyintel   \n",
              "4    NaN  [\"Two of New York City's largest pension funds...  energyintel   \n",
              "\n",
              "                                                 url Unnamed: 7  \n",
              "0  https://www.energyintel.com/0000017b-a7dc-de4c...        NaN  \n",
              "1  https://www.energyintel.com/0000017b-a7dc-de4c...        NaN  \n",
              "2  https://www.energyintel.com/0000017b-a7dc-de4c...        NaN  \n",
              "3  https://www.energyintel.com/0000017b-a7dc-de4c...        NaN  \n",
              "4  https://www.energyintel.com/0000017b-a7dc-de4c...        NaN  "
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the first few rows of the media dataset\n",
        "cleantech_media_data.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Unnamed: 0', 'title', 'date', 'author', 'content', 'domain', 'url',\n",
            "       'Unnamed: 7'],\n",
            "      dtype='object') \n",
            "\n",
            "[\"Qatar Petroleum ( QP) is targeting aggressive cuts in its greenhouse gas emissions as it prepares to launch Phase 2 of its planned 48 million ton per year LNG expansion. In its latest Sustainability Report published on Wednesday, QP said its goals include `` reducing the emissions intensity of Qatar's LNG facilities by 25% and of its upstream facilities by at least 15%. '' The company is also aiming to reduce gas flaring intensity across its upstream facilities by more than 75% and has raised its carbon capture and storage ambitions from 5 million tons/yr to 7 million tons/yr by 2027. About 2.2 million tons/yr of the carbon capture goal will come from the 32 million ton/yr Phase 1 of the LNG expansion, also known as the North Field East project. A further 1.1 million tons/yr will come from Phase 2, known as the North Field South project, which will raise Qatar's LNG capacity by a further 16 million tons/yr. Qatar currently has an LNG production capacity of around 78 million tons/yr and is eyeing a phased expansion to 126 million tons/yr. QP says it should be able to eliminate routine gas flaring by 2030, with methane emissions limited `` by setting a methane intensity target of 0.2% across all facilities by 2025. '' The company also plans to build some 1.6 gigawatts of solar energy capacity by 2025, half of which should come from the Siraj solar power project next year ( EIF Jan.22'20). Until this month, there had been little news about Phase 2 of Qatar's massive LNG expansion. But McDermott International said last week that it had been awarded the front-end engineering and design contract for five offshore wellhead platforms ( LNGI Jan.12'21). Bids for construction of all four trains for Phase 1 of the LNG expansion were submitted in September ( LNGI Sep.15'20). But QP judged them to be too expensive and none met its targeted 50-week construction schedule. Shortlisted contractors were asked to look for cost savings and submit new bids. The contract, which consultancy Rystad estimates to be worth around $ 35 billion, is expected to be awarded by Mar. 31. Shortly after the construction contract is awarded, QP is expected to select foreign investments partners to take stakes of up to 30% in the Phase 1 trains. Exxon Mobil, Royal Dutch Shell, Total, Chevron, ConocoPhillips and Eni have been shortlisted. QP has repeatedly said that it is prepared to proceed without international investment partners if it determines that the offers it receives are not sufficiently attractive. But the shortlisted companies are expected to bid aggressively for what is expected to be the world's lowest-cost and most environmentally friendly LNG ( LNGI Nov.9'20). Rafiq Latta, Nicosia\"] \n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "content\n",
              "<class 'str'>      9551\n",
              "<class 'float'>      42\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the column names\n",
        "print(cleantech_media_data.columns, \"\\n\")\n",
        "\n",
        "# Check the content of the first row\n",
        "print(cleantech_media_data[\"content\"][0], \"\\n\")\n",
        "\n",
        "# Check the type of the content column\n",
        "cleantech_media_data[\"content\"].apply(type).value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2874    NaN\n",
            "2943    NaN\n",
            "3832    NaN\n",
            "4907    NaN\n",
            "4911    NaN\n",
            "4916    NaN\n",
            "4972    NaN\n",
            "4975    NaN\n",
            "4996    NaN\n",
            "5011    NaN\n",
            "5047    NaN\n",
            "5048    NaN\n",
            "5062    NaN\n",
            "5100    NaN\n",
            "5145    NaN\n",
            "5175    NaN\n",
            "5191    NaN\n",
            "5194    NaN\n",
            "5201    NaN\n",
            "5203    NaN\n",
            "5240    NaN\n",
            "5253    NaN\n",
            "5256    NaN\n",
            "5285    NaN\n",
            "5303    NaN\n",
            "5313    NaN\n",
            "5396    NaN\n",
            "5400    NaN\n",
            "5403    NaN\n",
            "5408    NaN\n",
            "5441    NaN\n",
            "5447    NaN\n",
            "5458    NaN\n",
            "5481    NaN\n",
            "5517    NaN\n",
            "5520    NaN\n",
            "5539    NaN\n",
            "5558    NaN\n",
            "6716    NaN\n",
            "6724    NaN\n",
            "6730    NaN\n",
            "6741    NaN\n",
            "Name: content, dtype: object\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Filter out the float values\n",
        "print(\n",
        "    cleantech_media_data[\"content\"][\n",
        "        cleantech_media_data[\"content\"].apply(type) == float\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Print the number of float values\n",
        "len(\n",
        "    cleantech_media_data[\"content\"][\n",
        "        cleantech_media_data[\"content\"].apply(type) == float\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title:  0\n",
            "Date:  0\n",
            "Author:  9520\n",
            "Content:  42\n",
            "Domain:  0\n",
            "Url: ,  0\n"
          ]
        }
      ],
      "source": [
        "# Print missing values in each column\n",
        "print(\"Title: \", cleantech_media_data[\"title\"].isna().sum())\n",
        "\n",
        "print(\"Date: \", cleantech_media_data[\"date\"].isna().sum())\n",
        "\n",
        "print(\"Author: \", cleantech_media_data[\"author\"].isna().sum())\n",
        "\n",
        "print(\"Content: \", cleantech_media_data[\"content\"].isna().sum())\n",
        "\n",
        "print(\"Domain: \", cleantech_media_data[\"domain\"].isna().sum())\n",
        "\n",
        "print(\"Url: , \", cleantech_media_data[\"url\"].isna().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBZGlhwa4wUO"
      },
      "source": [
        "## Inspect the Data Structure\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cb7wcV4a4v81",
        "outputId": "625546de-4bed-47aa-a378-98b5c1871c83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 23 entries, 0 to 22\n",
            "Data columns (total 5 columns):\n",
            " #   Column          Non-Null Count  Dtype \n",
            "---  ------          --------------  ----- \n",
            " 0   example_id      23 non-null     int64 \n",
            " 1   question_id     23 non-null     int64 \n",
            " 2   question        23 non-null     object\n",
            " 3   relevant_chunk  23 non-null     object\n",
            " 4   article_url     23 non-null     object\n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 1.0+ KB\n",
            "None\n",
            "       example_id  question_id\n",
            "count    23.00000    23.000000\n",
            "mean     12.00000    10.869565\n",
            "std       6.78233     6.348259\n",
            "min       1.00000     1.000000\n",
            "25%       6.50000     5.500000\n",
            "50%      12.00000    11.000000\n",
            "75%      17.50000    16.500000\n",
            "max      23.00000    21.000000\n"
          ]
        }
      ],
      "source": [
        "# Get a concise summary of the DataFrame\n",
        "print(cleantech_patent_data.info())\n",
        "\n",
        "# Display statistical summary for numerical columns\n",
        "print(cleantech_patent_data.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYCaGy-FdEt6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyzZMlam7j4x"
      },
      "source": [
        "## Data Cleaning\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xG257m8S7mL3"
      },
      "source": [
        "### Remove Duplicates\n",
        "\n",
        "Identify and remove any duplicate entries in the datasets to prevent biased analyses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqW6hxlLNRLE",
        "outputId": "b304722d-5bd2-47ac-e541-81755913b2dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicates in media data: 0\n"
          ]
        }
      ],
      "source": [
        "# Check for duplicates in the media data\n",
        "print(\"Duplicates in media data:\", cleantech_media_data.duplicated().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KayTfm4l85Sx"
      },
      "source": [
        "Remove duplicates based on 'publication_number' as it should uniquely identify each patent\n",
        "This ensures that each patent is represented only once in the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Bg7sKwQr8_xO",
        "outputId": "90647983-59cc-4091-cb0e-ad1a64a14d37"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "Index(['publication_number'], dtype='object')",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9248\\820331748.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Checking and removing duplicates in the patent data based on 'publication_number'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m duplicate_counts = cleantech_patent_data.duplicated(\n\u001b[0m\u001b[0;32m      3\u001b[0m     subset=\"publication_number\").sum()\n\u001b[0;32m      4\u001b[0m print(\n\u001b[0;32m      5\u001b[0m     f\"Number of duplicate rows based on publication_number: {duplicate_counts}\")\n",
            "\u001b[1;32mc:\\Users\\samue\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   6697\u001b[0m         \u001b[1;31m# Otherwise, raise a KeyError, same as if you try to __getitem__ with a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6698\u001b[0m         \u001b[1;31m# key that doesn't exist.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6699\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6701\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6703\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6704\u001b[0m             \u001b[1;31m# GH#45236 This is faster than get_group_index below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyError\u001b[0m: Index(['publication_number'], dtype='object')"
          ]
        }
      ],
      "source": [
        "# Checking and removing duplicates in the patent data based on 'publication_number'\n",
        "duplicate_counts = cleantech_patent_data.duplicated(\n",
        "    subset=\"publication_number\").sum()\n",
        "print(\n",
        "    f\"Number of duplicate rows based on publication_number: {duplicate_counts}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcrzuJk09BnS"
      },
      "outputs": [],
      "source": [
        "# Remove these duplicate rows\n",
        "cleantech_patent_data = cleantech_patent_data.drop_duplicates(\n",
        "    subset=\"publication_number\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Mz9Vw7mP67k"
      },
      "source": [
        "The patent dataset contains columns with list-like structures, making them unhashable and problematic for drop_duplicates().\n",
        "We need to convert these columns to a hashable type (like string):\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzurHGYrbUTM",
        "outputId": "a8146af0-7c3c-479c-90fa-85c8299e6618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Duplicates in patent data based on text content: 87\n",
            "Number of duplicate entries in patent data: 87\n"
          ]
        }
      ],
      "source": [
        "# Further deduplication in patent data based on text content\n",
        "\n",
        "# Convert list-type columns to string for the purpose of identifying duplicates\n",
        "cleantech_patent_data[\"abstract_localized_str\"] = cleantech_patent_data[\n",
        "    \"abstract_localized\"\n",
        "].apply(str)\n",
        "print(\n",
        "    \"Duplicates in patent data based on text content:\",\n",
        "    cleantech_patent_data.duplicated(subset=[\"abstract_localized_str\"]).sum(),\n",
        ")\n",
        "\n",
        "# Check for duplicates in the patent dataset\n",
        "patent_duplicates = cleantech_patent_data.duplicated(subset=[\"abstract_localized_str\"])\n",
        "print(\"Number of duplicate entries in patent data:\", patent_duplicates.sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxmGDEBJQLTH",
        "outputId": "13359d4a-ab17-4a51-d36d-f04fbe8f6295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final shape of patent data after cleaning: (13325, 8)\n"
          ]
        }
      ],
      "source": [
        "# Drop duplicates\n",
        "cleantech_patent_data = cleantech_patent_data.drop_duplicates(\n",
        "    subset=[\"abstract_localized_str\"]\n",
        ")\n",
        "\n",
        "# Cleaning up by dropping the temporary string column\n",
        "cleantech_patent_data = cleantech_patent_data.drop(columns=[\"abstract_localized_str\"])\n",
        "\n",
        "# Verify the operation\n",
        "print(\"Final shape of patent data after cleaning:\", cleantech_patent_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6lmAbB-5P60"
      },
      "source": [
        "## Handle Nested JSON Fields\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHYrpNxi5b1r"
      },
      "source": [
        "We have the fields title_localized and abstract_localized are nested, so extract relevant information:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXgjlr0m5Ouc",
        "outputId": "b0682288-1883-4afb-c394-be387eec6abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               title  \\\n",
            "0  Adaptable DC-AC Inverter Drive System and Oper...   \n",
            "1  System for providing the energy from a single ...   \n",
            "2      Verfahren zum steuern einer windenergieanlage   \n",
            "4  Control method for optimizing solar-to-power e...   \n",
            "5  Low-carbon running saline wastewater treatment...   \n",
            "\n",
            "                                            abstract  \n",
            "0  Disclosed is an adaptable DC-AC inverter syste...  \n",
            "1  In accordance with an example embodiment, a so...  \n",
            "2  Verfahren zum Steuern einer Windenergieanlage ...  \n",
            "4  A control method for optimizing a solar-to-pow...  \n",
            "5  本发明公开了一种应用太阳能和环路热管的低碳运行含盐废水处理系统及方法，属于含盐废水低碳处理领...  \n"
          ]
        }
      ],
      "source": [
        "# Extracting 'text' from 'title_localized' and 'abstract_localized'\n",
        "cleantech_patent_data[\"title\"] = cleantech_patent_data[\"title_localized\"].apply(\n",
        "    lambda x: x[0][\"text\"] if x else None\n",
        ")\n",
        "cleantech_patent_data[\"abstract\"] = cleantech_patent_data[\"abstract_localized\"].apply(\n",
        "    lambda x: x[0][\"text\"] if x else None\n",
        ")\n",
        "\n",
        "# Check the result\n",
        "print(cleantech_patent_data[[\"title\", \"abstract\"]].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ix6YvJr-5OhV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuhLmjtB_Q0f"
      },
      "source": [
        "## Handling Missing Values\n",
        "\n",
        "Determine if any columns have a significant number of missing values and decide whether to impute or remove these entries.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryFm4cx1DaA3",
        "outputId": "14c3fd7e-6e1f-4397-d769-eca5bfc3abd3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in media data:\n",
            "Unnamed: 0       0\n",
            "title            0\n",
            "date             0\n",
            "author        9562\n",
            "content          0\n",
            "domain           0\n",
            "url              0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Check for missing values before removal\n",
        "print(\"Missing values in media data:\")\n",
        "print(cleantech_media_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWYbvtzJcP-_"
      },
      "outputs": [],
      "source": [
        "# Dropping the 'Unnamed: 0' column as it appears to be an auto-generated index with no intrinsic meaning.\n",
        "cleantech_media_data = cleantech_media_data.drop(columns=[\"Unnamed: 0\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvoBxR-zcP0M"
      },
      "source": [
        "This column likely originated from an index in the source file and does not provide useful information for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bhkIciRSNtf-"
      },
      "outputs": [],
      "source": [
        "# Dropping the 'author' column if not needed\n",
        "cleantech_media_data.drop(\"author\", axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-JbqV_Frcrmz"
      },
      "source": [
        "Dropping the 'author' column due to a large number of missing values (9562 out of total).\n",
        "Given that the authorship is not central to our analysis of cleantech trends and innovations, \n",
        "and imputation of these missing values is not feasible without reliable auxiliary information, \n",
        "we remove this column to focus on more complete and relevant data aspects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpGL2T83N58O",
        "outputId": "6e368b95-3841-421e-c989-2dcfae8d2d1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9593 entries, 0 to 9592\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   title    9593 non-null   object\n",
            " 1   date     9593 non-null   object\n",
            " 2   content  9593 non-null   object\n",
            " 3   domain   9593 non-null   object\n",
            " 4   url      9593 non-null   object\n",
            "dtypes: object(5)\n",
            "memory usage: 374.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Final verification of data structure and types\n",
        "print(cleantech_media_data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBKf2hU4ONDg",
        "outputId": "3621456b-6898-48c5-bb97-7ac4db638c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values in patent dataset:\n",
            "publication_number    0\n",
            "application_number    0\n",
            "country_code          0\n",
            "title_localized       0\n",
            "abstract_localized    0\n",
            "publication_date      0\n",
            "inventor              0\n",
            "cpc                   0\n",
            "title                 0\n",
            "abstract              0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Show the count of missing values in the patent dataset\n",
        "print(\"Missing values in patent dataset:\")\n",
        "print(cleantech_patent_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u2B_ODn55s77",
        "outputId": "0820df1c-9b81-4f8a-de52-f5927ce00c98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "publication_number       0\n",
            "application_number       0\n",
            "country_code             0\n",
            "title_localized          0\n",
            "abstract_localized       0\n",
            "publication_date         0\n",
            "inventor              4973\n",
            "cpc                   4867\n",
            "title                    0\n",
            "abstract                 0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Replace empty lists or None with NaN\n",
        "cleantech_patent_data = cleantech_patent_data.applymap(lambda x: pd.NA if not x else x)\n",
        "\n",
        "# Check for missing values\n",
        "print(cleantech_patent_data.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8svxAWQ_VXE"
      },
      "source": [
        "## Data Type Consistency\n",
        "\n",
        "Ensure that all columns are of the correct data type, such as converting dates to datetime objects for easier analysis later\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KSkBxl1SHQIH",
        "outputId": "940bdd31-d8ab-4a7b-d3bf-08f204599ab1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "title              object\n",
            "date       datetime64[ns]\n",
            "content            object\n",
            "domain             object\n",
            "url                object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "# Convert date columns to datetime format\n",
        "cleantech_media_data[\"date\"] = pd.to_datetime(cleantech_media_data[\"date\"])\n",
        "\n",
        "# Verify the data types\n",
        "print(cleantech_media_data.dtypes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3-gCEFb53AE",
        "outputId": "8622ce0e-76ce-4ee3-acee-a6172fbd0808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0   1970-01-01 00:00:00.020220728\n",
            "1   1970-01-01 00:00:00.020220728\n",
            "2   1970-01-01 00:00:00.020220727\n",
            "4   1970-01-01 00:00:00.020220726\n",
            "5   1970-01-01 00:00:00.020220722\n",
            "Name: publication_date, dtype: datetime64[ns]\n"
          ]
        }
      ],
      "source": [
        "# Convert 'publication_date' to datetime format\n",
        "cleantech_patent_data[\"publication_date\"] = pd.to_datetime(\n",
        "    cleantech_patent_data[\"publication_date\"], errors=\"coerce\"\n",
        ")\n",
        "\n",
        "# Verify the conversion\n",
        "print(cleantech_patent_data[\"publication_date\"].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXzBaMMxZ3o_"
      },
      "source": [
        "## Final Data Overview\n",
        "\n",
        "After cleaning, we provide an overview of the cleaned datasets to verify that they are ready for analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n_MvoV_Z3Wg",
        "outputId": "616a1f10-a508-41bf-d5d8-6da8b31d05e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 9593 entries, 0 to 9592\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype         \n",
            "---  ------   --------------  -----         \n",
            " 0   title    9593 non-null   object        \n",
            " 1   date     9593 non-null   datetime64[ns]\n",
            " 2   content  9593 non-null   object        \n",
            " 3   domain   9593 non-null   object        \n",
            " 4   url      9593 non-null   object        \n",
            "dtypes: datetime64[ns](1), object(4)\n",
            "memory usage: 374.9+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(cleantech_media_data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8t7iKMjaEyJ",
        "outputId": "c6afb46a-b6aa-4ca4-a9bb-aa02a82f11aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 13325 entries, 0 to 29997\n",
            "Data columns (total 10 columns):\n",
            " #   Column              Non-Null Count  Dtype         \n",
            "---  ------              --------------  -----         \n",
            " 0   publication_number  13325 non-null  object        \n",
            " 1   application_number  13325 non-null  object        \n",
            " 2   country_code        13325 non-null  object        \n",
            " 3   title_localized     13325 non-null  object        \n",
            " 4   abstract_localized  13325 non-null  object        \n",
            " 5   publication_date    13325 non-null  datetime64[ns]\n",
            " 6   inventor            8352 non-null   object        \n",
            " 7   cpc                 8458 non-null   object        \n",
            " 8   title               13325 non-null  object        \n",
            " 9   abstract            13325 non-null  object        \n",
            "dtypes: datetime64[ns](1), object(9)\n",
            "memory usage: 1.1+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(cleantech_patent_data.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZQWNgG6KcsZ"
      },
      "source": [
        "## Saving the Cleaned Datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mWMep1IKbo3",
        "outputId": "82ab13b4-26ef-4d6b-a432-c09cf1f147c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned media data saved to /content/drive/My Drive/CLT/cleantech_media_cleaned.csv\n",
            "Cleaned patent data saved to /content/drive/My Drive/CLT/cleantech_patent_cleaned.csv\n"
          ]
        }
      ],
      "source": [
        "# After completing all data cleaning steps\n",
        "\n",
        "# Specify the path for saving the cleaned datasets\n",
        "cleaned_media_data_path = \"/content/drive/My Drive/CLT/cleantech_media_cleaned.csv\"\n",
        "cleaned_patent_data_path = \"/content/drive/My Drive/CLT/cleantech_patent_cleaned.csv\"\n",
        "\n",
        "# Save the cleaned media dataset\n",
        "cleantech_media_data.to_csv(cleaned_media_data_path, index=False)\n",
        "print(f\"Cleaned media data saved to {cleaned_media_data_path}\")\n",
        "\n",
        "# Save the cleaned patent dataset\n",
        "cleantech_patent_data.to_csv(cleaned_patent_data_path, index=False)\n",
        "print(f\"Cleaned patent data saved to {cleaned_patent_data_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b2j3eFS_fEJw"
      },
      "source": [
        "# Text Preprocessing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hztRK6tI-88"
      },
      "source": [
        "## Importing Necessary Libraries\n",
        "\n",
        "We start by importing the libraries needed for data manipulation and text preprocessing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAB4Vp_EgE6a"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmH6n8OjJNzA",
        "outputId": "f1f90433-dcec-44e3-e1a6-d64bd47d62f8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ensure that NLTK's tokenizers and stopwords data are available\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"wordnet\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JI1PflbJUn3"
      },
      "source": [
        "### Text Preprocessing Function\n",
        "\n",
        "This function will be used to clean and preprocess text data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zk1kRUX3JcZT"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    \"\"\"\n",
        "    Function to preprocess text data by lowering case, removing punctuation,\n",
        "    tokenizing, removing stopwords, and lemmatizing.\n",
        "    \"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    # Remove punctuation and special characters\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    # Tokenization\n",
        "    tokens = nltk.word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return \" \".join(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-C5IxggKvoA"
      },
      "source": [
        "### Loading and Preprocessing the Text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ol6Acz-dKuY-",
        "outputId": "17003157-259f-44a9-eaf6-cc2b944eb1c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cleaned Cleantech Media Data loaded successfully.\n",
            "                                               title        date  \\\n",
            "0  Qatar to Slash Emissions as LNG Expansion Adva...  2021-01-13   \n",
            "1               India Launches Its First 700 MW PHWR  2021-01-15   \n",
            "2              New Chapter for US-China Energy Trade  2021-01-20   \n",
            "3  Japan: Slow Restarts Cast Doubt on 2030 Energy...  2021-01-22   \n",
            "4     NYC Pension Funds to Divest Fossil Fuel Shares  2021-01-25   \n",
            "\n",
            "                                             content       domain  \\\n",
            "0  [\"Qatar Petroleum ( QP) is targeting aggressiv...  energyintel   \n",
            "1  [\"• Nuclear Power Corp. of India Ltd. ( NPCIL)...  energyintel   \n",
            "2  [\"New US President Joe Biden took office this ...  energyintel   \n",
            "3  [\"The slow pace of Japanese reactor restarts c...  energyintel   \n",
            "4  [\"Two of New York City's largest pension funds...  energyintel   \n",
            "\n",
            "                                                 url  \n",
            "0  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
            "1  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
            "2  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
            "3  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
            "4  https://www.energyintel.com/0000017b-a7dc-de4c...  \n",
            "\n",
            "Cleaned Cleantech Patent Data loaded successfully.\n",
            "  publication_number application_number country_code  \\\n",
            "0   US-2022239235-A1  US-202217717397-A           US   \n",
            "1   US-2022239251-A1  US-202217580956-A           US   \n",
            "2      EP-4033090-A1      EP-21152924-A           EP   \n",
            "3     US-11396827-B2  US-202117606042-A           US   \n",
            "4     CN-114772674-A  CN-202210500131-A           CN   \n",
            "\n",
            "                                     title_localized  \\\n",
            "0  [{'text': 'Adaptable DC-AC Inverter Drive Syst...   \n",
            "1  [{'text': 'System for providing the energy fro...   \n",
            "2  [{'text': 'Verfahren zum steuern einer windene...   \n",
            "3  [{'text': 'Control method for optimizing solar...   \n",
            "4  [{'text': 'Low-carbon running saline wastewate...   \n",
            "\n",
            "                                  abstract_localized  \\\n",
            "0  [{'text': 'Disclosed is an adaptable DC-AC inv...   \n",
            "1  [{'text': 'In accordance with an example embod...   \n",
            "2  [{'text': 'Verfahren zum Steuern einer Windene...   \n",
            "3  [{'text': 'A control method for optimizing a s...   \n",
            "4  [{'text': '本发明公开了一种应用太阳能和环路热管的低碳运行含盐废水处理系统及方法，...   \n",
            "\n",
            "                publication_date  \\\n",
            "0  1970-01-01 00:00:00.020220728   \n",
            "1  1970-01-01 00:00:00.020220728   \n",
            "2  1970-01-01 00:00:00.020220727   \n",
            "3  1970-01-01 00:00:00.020220726   \n",
            "4  1970-01-01 00:00:00.020220722   \n",
            "\n",
            "                                            inventor  \\\n",
            "0                                                NaN   \n",
            "1                                                NaN   \n",
            "2  ['Schaper, Ulf', 'von Aswege, Enno', 'Gerke Fu...   \n",
            "3                                                NaN   \n",
            "4                                                NaN   \n",
            "\n",
            "                                                 cpc  \\\n",
            "0  [{'code': 'H02M7/5395', 'inventive': True, 'fi...   \n",
            "1  [{'code': 'H02S40/38', 'inventive': True, 'fir...   \n",
            "2  [{'code': 'F03D7/0276', 'inventive': True, 'fi...   \n",
            "3  [{'code': 'F24S50/00', 'inventive': True, 'fir...   \n",
            "4                                                NaN   \n",
            "\n",
            "                                               title  \\\n",
            "0  Adaptable DC-AC Inverter Drive System and Oper...   \n",
            "1  System for providing the energy from a single ...   \n",
            "2      Verfahren zum steuern einer windenergieanlage   \n",
            "3  Control method for optimizing solar-to-power e...   \n",
            "4  Low-carbon running saline wastewater treatment...   \n",
            "\n",
            "                                            abstract  \n",
            "0  Disclosed is an adaptable DC-AC inverter syste...  \n",
            "1  In accordance with an example embodiment, a so...  \n",
            "2  Verfahren zum Steuern einer Windenergieanlage ...  \n",
            "3  A control method for optimizing a solar-to-pow...  \n",
            "4  本发明公开了一种应用太阳能和环路热管的低碳运行含盐废水处理系统及方法，属于含盐废水低碳处理领...  \n"
          ]
        }
      ],
      "source": [
        "# Define the paths where the cleaned datasets were saved\n",
        "media_data_cleaned_path = \"/content/drive/My Drive/CLT/cleantech_media_cleaned.csv\"\n",
        "patent_data_cleaned_path = \"/content/drive/My Drive/CLT/cleantech_patent_cleaned.csv\"\n",
        "\n",
        "# Loading the cleaned media dataset\n",
        "media_data = pd.read_csv(media_data_cleaned_path)\n",
        "print(\"Cleaned Cleantech Media Data loaded successfully.\")\n",
        "print(media_data.head())  # Display the first few rows to verify the data\n",
        "\n",
        "# Loading the cleaned patent dataset\n",
        "patent_data = pd.read_csv(patent_data_cleaned_path)\n",
        "print(\"\\nCleaned Cleantech Patent Data loaded successfully.\")\n",
        "print(patent_data.head())  # Display the first few rows to verify the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDMLvzyXfEVL"
      },
      "source": [
        "### Applying Text Preprocessing\n",
        "\n",
        "We now apply the defined text preprocessing function to relevant columns in the datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gQqWjMhyJuWy"
      },
      "outputs": [],
      "source": [
        "# Preprocess 'title' and 'content' columns in the media dataset\n",
        "media_data[\"title_preprocessed\"] = media_data[\"title\"].apply(preprocess_text)\n",
        "media_data[\"content_preprocessed\"] = media_data[\"content\"].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92lgwujRNDMU",
        "outputId": "ef8cbe65-89c9-47cf-e1a1-b3e15614739a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Media Data Preprocessed Sample:\n",
            "                                               title  \\\n",
            "0  Qatar to Slash Emissions as LNG Expansion Adva...   \n",
            "1               India Launches Its First 700 MW PHWR   \n",
            "2              New Chapter for US-China Energy Trade   \n",
            "3  Japan: Slow Restarts Cast Doubt on 2030 Energy...   \n",
            "4     NYC Pension Funds to Divest Fossil Fuel Shares   \n",
            "\n",
            "                                title_preprocessed  \\\n",
            "0       qatar slash emission lng expansion advance   \n",
            "1                   india launch first 700 mw phwr   \n",
            "2                 new chapter uschina energy trade   \n",
            "3  japan slow restarts cast doubt 2030 energy plan   \n",
            "4        nyc pension fund divest fossil fuel share   \n",
            "\n",
            "                                             content  \\\n",
            "0  [\"Qatar Petroleum ( QP) is targeting aggressiv...   \n",
            "1  [\"• Nuclear Power Corp. of India Ltd. ( NPCIL)...   \n",
            "2  [\"New US President Joe Biden took office this ...   \n",
            "3  [\"The slow pace of Japanese reactor restarts c...   \n",
            "4  [\"Two of New York City's largest pension funds...   \n",
            "\n",
            "                                content_preprocessed  \n",
            "0  qatar petroleum qp targeting aggressive cut gr...  \n",
            "1  nuclear power corp india ltd npcil synchronize...  \n",
            "2  new u president joe biden took office week usc...  \n",
            "3  slow pace japanese reactor restarts continues ...  \n",
            "4  two new york city largest pension fund say div...  \n"
          ]
        }
      ],
      "source": [
        "# Displaying a sample of the preprocessed data\n",
        "print(\"Media Data Preprocessed Sample:\")\n",
        "print(\n",
        "    media_data[\n",
        "        [\"title\", \"title_preprocessed\", \"content\", \"content_preprocessed\"]\n",
        "    ].head()\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esuyULZuNCvX"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFp7pHnMMjz8",
        "outputId": "49417350-038b-469d-eb2b-671e1579cff6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Patent Data Preprocessed Sample:\n",
            "                                  title_preprocessed  \\\n",
            "0  text adaptable dcac inverter drive system oper...   \n",
            "1  text system providing energy single contiguous...   \n",
            "2  text verfahren zum steuern einer windenergiean...   \n",
            "3  text control method optimizing solartopower ef...   \n",
            "4  text lowcarbon running saline wastewater treat...   \n",
            "\n",
            "                               abstract_preprocessed  \n",
            "0  text disclosed adaptable dcac inverter system ...  \n",
            "1  text accordance example embodiment solar energ...  \n",
            "2  text verfahren zum steuern einer windenergiean...  \n",
            "3  text control method optimizing solartopower ef...  \n",
            "4  text 本发明公开了一种应用太阳能和环路热管的低碳运行含盐废水处理系统及方法属于含盐废水低...  \n"
          ]
        }
      ],
      "source": [
        "# Preprocessing the 'title_localized' and 'abstract_localized' columns in the patent dataset\n",
        "patent_data[\"title_preprocessed\"] = patent_data[\"title_localized\"].apply(\n",
        "    preprocess_text\n",
        ")\n",
        "patent_data[\"abstract_preprocessed\"] = patent_data[\"abstract_localized\"].apply(\n",
        "    preprocess_text\n",
        ")\n",
        "\n",
        "# Display a sample of the preprocessed patent data to verify\n",
        "print(\"\\nPatent Data Preprocessed Sample:\")\n",
        "print(patent_data[[\"title_preprocessed\", \"abstract_preprocessed\"]].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jSOh1wkbPMHO"
      },
      "source": [
        "## Saving Text preprocessed Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LiwFcGGPH88",
        "outputId": "8cc09f19-5f59-4aa0-f40a-7054145c69a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessed media dataset saved to: /content/drive/My Drive/CLT/cleantech_media_preprocessed.csv\n",
            "Preprocessed patent dataset saved to: /content/drive/My Drive/CLT/cleantech_patent_preprocessed.csv\n"
          ]
        }
      ],
      "source": [
        "# Define the paths for saving the preprocessed datasets\n",
        "preprocessed_media_path = \"/content/drive/My Drive/CLT/cleantech_media_preprocessed.csv\"\n",
        "preprocessed_patent_path = (\n",
        "    \"/content/drive/My Drive/CLT/cleantech_patent_preprocessed.csv\"\n",
        ")\n",
        "\n",
        "# Save the preprocessed media dataset to a new CSV file\n",
        "media_data.to_csv(preprocessed_media_path, index=False)\n",
        "print(f\"Preprocessed media dataset saved to: {preprocessed_media_path}\")\n",
        "\n",
        "# Save the preprocessed patent dataset to a new CSV file\n",
        "patent_data.to_csv(preprocessed_patent_path, index=False)\n",
        "print(f\"Preprocessed patent dataset saved to: {preprocessed_patent_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krobdnjgJ6dE"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "The text data from both the Cleantech Media Dataset and the Cleantech Google Patent Dataset has been successfully preprocessed.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
